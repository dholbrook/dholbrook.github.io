---
layout: post
title: Scala External DSL and Combinator Parsing experimentation
date: 2010-03-21
---

<p>Yesterday I was looking around on the inter-webs for a Scala project that was “<a href="http://ibatis.apache.org/">iBatis</a>” like, but more Scala oriented.&#160; I found some cool stuff (<a href="http://www.sts.tu-harburg.de/people/mi.garcia/ScalaQL/">ScalaQL</a>, and <a href="http://github.com/p3t0r/scala-sql-dsl">scala-sql-dsl</a> for example) but nothing quite what I was looking for.</p>  <p>I kind of chewed on what exactly it was that I was looking for and this is my 10k/foot feature list:</p>  <ul>   <li>Ability to define the underlying data store in a DSL that can be understood by Scala </li>    <li>Ability to map Scala classes to JDBC results by binding to artifacts of the data store </li> </ul>  <p>This is more or less what iBatis accomplishes with xml (now annotations) and a bunch of reflection.&#160; I’d like to see it done without XML and minimal reflection.</p>  <p>That sent me down the rabbit hole on how exactly one goes about defining a DSL in scala.&#160; I re-read chapter 31 in <a href="http://www.artima.com/shop/programming_in_scala">Programming in Scala</a>.&#160; I also read chapter 11 in <a href="http://programming-scala.labs.oreilly.com/ch11.html">Programming Scala</a>.&#160; Then I took a stab at writing a parser combinator for a very, very small subset of the “CREATE TABLE” DDL syntax for SQL.</p>  <pre class="brush: scala">import scala.util.parsing.combinator._<br /><br />class TableDdlParser extends JavaTokenParsers {<br />  <br />  def tables: Parser[Map[String, Any]] = rep(table) ^^ { Map() ++ _ }<br />  <br />  def table: Parser[(String,Any)] = <br />    (&quot;TABLE&quot; ~ tableName ~ columns <br />       ^^ { case &quot;TABLE&quot; ~ tableName ~ tableContents =&gt; (tableName,tableContents) })<br />  <br />  def tableName: Parser[String] = ident ^^ { case ident =&gt; ident }<br />  <br />  def columns: Parser[Map[String, Any]] = &quot;(&quot;~&gt; repsep(column, &quot;,&quot;) &lt;~&quot;)&quot; ^^ { Map() ++ _ }<br />  <br />  def column: Parser[(String,Any)] = <br />    columnName ~ dataType ^^ { case columnName ~ dataType =&gt; (columnName,dataType) }<br />    <br />  def columnName: Parser[String] = ident ^^ { case ident =&gt; ident }<br />  <br />  def dataType: Parser[Any] = &quot;VARCHAR&quot; | &quot;INTEGER&quot;<br />  <br />}<br /><br />object TableDdlParserRunner extends TableDdlParser {<br />  <br />  def main(args: Array[String]) {<br />    val input = <br />      &quot;&quot;&quot;TABLE person (first_name VARCHAR, last_name VARCHAR, age INTEGER)<br />         TABLE place (city VARCHAR, state VARCHAR)&quot;&quot;&quot;<br />    println(parseAll(tables,input))<br />  }<br /> <br />}</pre><br /><br /><p>Here is the output</p><br /><br /><pre class="brush: text">[2.51] parsed: <br />Map(person -&gt; Map(first_name -&gt; VARCHAR, <br />                  last_name -&gt; VARCHAR, <br />                  age -&gt; INTEGER), <br />    place -&gt; Map(city -&gt; VARCHAR, <br />                 state -&gt; VARCHAR))</pre><br /><br /><p>This experiment only supports two data types (VARCHAR and INTEGER), without any of the other metadata that is required for those types.&#160; I just wanted a feel for how hard it would be to write and didn’t want to get bogged down in the details.&#160; It turned out to be quite a bit easier than I thought it would be. </p><br /><br /><p>Next up is to figure out the best way to map this DDL information to a scala class (If I don’t get distracted by something else first).</p>
